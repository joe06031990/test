// Defines the start of a declarative Jenkins pipeline.
pipeline {
    // Specifies that the pipeline can run on any available Jenkins agent.
    agent any

    // Sets up an automatic schedule for the pipeline to run.
    triggers {
        // 'H/2 * * * *' means the job will run approximately every hour.
        // cron('H/2 * * * *')
    }

    // Defines environment variables that will be available throughout the pipeline.
    environment {
        // Securely loads the Grafana API key from Jenkins credentials.
        GRAFANA_API_KEY = credentials('GRAFANA_API_KEY')
        // The URL of your Grafana instance.
        GRAFANA_URL = "https://jstest2025.grafana.net"
        // The name of the root directory where backups will be stored in the Git repository.
        GRAFANA_BACKUP_DIR = "playground_nonprd"
    }

    // Contains all the main work stages of the pipeline.
    stages {
        // The first stage: responsible for checking out code from your Git repository.
        stage('Checkout Git Repository') {
            steps {
                // The 'checkout' step clones or updates the specified Git repository and branch.
                checkout([$class: 'GitSCM', branches: [[name: '*/master']],
                          userRemoteConfigs: [[credentialsId: 'github-creds1', url: 'https://github.com/joe06031990/test']]])
            }
        }

        // THIS STAGE WILL NOW ONLY RUN ON THE 'master' BRANCH.
        // This is critical for preventing builds on other branches from overwriting the backup.
        stage('Run Grafana Dashboard Backup') {
            when {
                branch 'master'
            }
            steps {
                // A 'script' block allows for more complex Groovy code and logic.
                script {
                    // A multiline string variable in Groovy that holds the entire bash script.
                    def grafanaBackupScriptContent = '''#!/bin/bash
                        # 'set -e' ensures the script will exit immediately if a command fails.
                        set -e
                        # 'set -x' prints each command to the log before it is executed, useful for debugging.
                        set -x
                        
                        CURL_CMD="/usr/bin/curl"
                        JQ_CMD="/usr/bin/jq"

                        # Sanity checks to ensure required tools and variables are present.
                        if [ ! -f "${CURL_CMD}" ]; then
                            echo "Error: 'curl' not found at ${CURL_CMD}. Please install it."
                            exit 1
                        fi
                        if [ ! -f "${JQ_CMD}" ]; then
                            echo "Error: 'jq' not found at ${JQ_CMD}. Please install it."
                            exit 1
                        fi
                        if [ -z "${GRAFANA_URL}" ] || [ -z "${GRAFANA_API_KEY}" ] || [ -z "${GRAFANA_BACKUP_DIR}" ]; then
                            echo "Missing required environment variables."
                            exit 1
                        fi

                        echo "Starting Grafana dashboard backup from ${GRAFANA_URL} to ${GRAFANA_BACKUP_DIR}"

                        # This command enables "mirror" mode by deleting the old backup directory.
                        # This ensures dashboards deleted in Grafana are also removed from Git.
                        rm -rf "${GRAFANA_BACKUP_DIR}"
                        mkdir -p "${GRAFANA_BACKUP_DIR}"

                        # A function to clean up dashboard titles to make them safe for use as filenames.
                        sanitize_filename() {
                            echo "$1" | sed 's/[^a-zA-Z0-9._-]/_/g' | sed 's/__*/_/g' | sed 's/^_//;s/_$//'
                        }

                        # ==================== AUTO-DISCOVERY SECTION ====================
                        echo "ðŸ” Auto-discovering all folders from Grafana API..."
                        
                        # Fetch all folders from Grafana API - THIS IS THE AUTO-DISCOVERY
                        ALL_FOLDERS=$(${CURL_CMD} -s -H "Authorization: Bearer ${GRAFANA_API_KEY}" "${GRAFANA_URL}/api/folders")
                        
                        # Create dynamic folder mapping that preserves structure
                        declare -A AUTO_FOLDER_MAP
                        
                        # Handle special root cases
                        AUTO_FOLDER_MAP["playground"]=""          # Root playground dashboards
                        AUTO_FOLDER_MAP["General"]=""             # Default folder dashboards
                        
                        # Build parent folder lookup table first
                        declare -A PARENT_LOOKUP
                        echo "${ALL_FOLDERS}" | ${JQ_CMD} -c '.[]' | while read -r folder; do
                            FOLDER_TITLE=$(echo "${folder}" | ${JQ_CMD} -r '.title')
                            FOLDER_UID=$(echo "${folder}" | ${JQ_CMD} -r '.uid')
                            echo "PARENT_LOOKUP[\"${FOLDER_UID}\"]=\"${FOLDER_TITLE}\"" >> /tmp/parent_lookup.sh
                        done
                        
                        # Load parent lookup
                        source /tmp/parent_lookup.sh 2>/dev/null || true
                        
                        # Process each folder and create proper mappings
                        echo "${ALL_FOLDERS}" | ${JQ_CMD} -c '.[]' | while read -r folder; do
                            FOLDER_TITLE=$(echo "${folder}" | ${JQ_CMD} -r '.title')
                            FOLDER_UID=$(echo "${folder}" | ${JQ_CMD} -r '.uid')
                            PARENT_UID=$(echo "${folder}" | ${JQ_CMD} -r '.parentUid // empty')
                            
                            if [ -n "${PARENT_UID}" ] && [[ -v PARENT_LOOKUP["${PARENT_UID}"] ]]; then
                                # This is a subfolder
                                PARENT_TITLE="${PARENT_LOOKUP["${PARENT_UID}"]}"
                                if [[ "${PARENT_TITLE}" == "playground" ]]; then
                                    FOLDER_SANITIZED=$(sanitize_filename "${FOLDER_TITLE}")
                                    AUTO_PATH="${FOLDER_SANITIZED}"
                                    echo " Subfolder discovered: '${FOLDER_TITLE}' -> '${AUTO_PATH}'"
                                    echo "AUTO_FOLDER_MAP[\"${FOLDER_TITLE}\"]=\"${AUTO_PATH}\"" >> /tmp/auto_folders.sh
                                fi
                            fi
                        done
                        
                        # Load all auto-discovered mappings
                        source /tmp/auto_folders.sh 2>/dev/null || true
                        
                        echo " Auto-discovery complete. Found ${#AUTO_FOLDER_MAP[@]} folder mappings"
                        
                        # Debug: Show all discovered mappings
                        for folder in "${!AUTO_FOLDER_MAP[@]}"; do
                            echo "   '${folder}' -> '${AUTO_FOLDER_MAP[$folder]}'"
                        done
                        # ================================================================

                        # Fetches a list of metadata for all dashboards from the Grafana API.
                        ALL_DASHBOARDS_META=$(${CURL_CMD} -s -H "Authorization: Bearer ${GRAFANA_API_KEY}" "${GRAFANA_URL}/api/search?type=dash-db&query=")

                        PROCESSED_DASHBOARD_UIDS=""

                        # Processes the list of dashboards one by one using a 'while' loop.
                        echo "${ALL_DASHBOARDS_META}" | ${JQ_CMD} -c '.[]' | while read -r DASHBOARD_META_INFO; do
                            DASHBOARD_UID=$(echo "${DASHBOARD_META_INFO}" | ${JQ_CMD} -r '.uid')
                            DASHBOARD_TITLE=$(echo "${DASHBOARD_META_INFO}" | ${JQ_CMD} -r '.title')
                            CLEAN_FOLDER_TITLE=$(echo "${DASHBOARD_META_INFO}" | ${JQ_CMD} -r '.folderTitle // "General"' | tr -d '\\n\\r\\t')

                            # Only process dashboards in playground or its subfolders
                            if [[ "${CLEAN_FOLDER_TITLE}" != "playground" && -z "${AUTO_FOLDER_MAP[${CLEAN_FOLDER_TITLE}]}" ]]; then
                                echo "Skipping dashboard '${DASHBOARD_TITLE}' in folder '${CLEAN_FOLDER_TITLE}'"
                                continue
                            fi

                            if [[ "${PROCESSED_DASHBOARD_UIDS}" == *"${DASHBOARD_UID}"* ]]; then
                                continue
                            fi

                            TARGET_GIT_RELATIVE_PATH="${AUTO_FOLDER_MAP[${CLEAN_FOLDER_TITLE}]}"
                            SANITIZED_DASH_TITLE=$(sanitize_filename "${DASHBOARD_TITLE}")
                            CURRENT_SAVE_DIR="${GRAFANA_BACKUP_DIR}"
                            if [ -n "${TARGET_GIT_RELATIVE_PATH}" ]; then
                                CURRENT_SAVE_DIR="${GRAFANA_BACKUP_DIR}/${TARGET_GIT_RELATIVE_PATH}"
                            fi
                            mkdir -p "${CURRENT_SAVE_DIR}"

                            filename="${SANITIZED_DASH_TITLE}.json"
                            filepath="${CURRENT_SAVE_DIR}/${filename}"

                            DASHBOARD_DATA=$(${CURL_CMD} -s -H "Authorization: Bearer ${GRAFANA_API_KEY}" "${GRAFANA_URL}/api/dashboards/uid/${DASHBOARD_UID}")
                            
                            if [ -n "${DASHBOARD_DATA}" ] && [ "$(${JQ_CMD} -r '.dashboard.title' <<< "${DASHBOARD_DATA}")" != "null" ]; then
                                echo "${DASHBOARD_DATA}" | ${JQ_CMD} -r '.dashboard' > "${filepath}"
                                PROCESSED_DASHBOARD_UIDS="${PROCESSED_DASHBOARD_UIDS} ${DASHBOARD_UID}"
                                echo " Saved: ${filepath}"
                            fi
                        done

                        # Cleanup temporary files
                        rm -f /tmp/auto_folders.sh /tmp/parent_lookup.sh

                        echo " Backup complete - all playground dashboards and subfolders processed!"
                    '''

                    writeFile(file: 'run_grafana_backup.sh', text: grafanaBackupScriptContent)
                    sh 'chmod +x run_grafana_backup.sh'
                    sh 'bash ./run_grafana_backup.sh'
                }
            }
        }

        // THIS STAGE WILL NOW ONLY RUN ON THE 'master' BRANCH.
        stage('Commit and Push Changes to Git') {
            when {
                branch 'master'
            }
            steps {
                script {
                    sh "git config user.email 'jenkins@test.com'"
                    sh "git config user.name 'Jenkins Automated Backup'"
                    // Use 'git add --all' to ensure deleted files are staged for commit.
                    sh "git add --all ${env.GRAFANA_BACKUP_DIR}"

                    // Checks if there are any actual changes to commit.
                    def changes = sh(returnStatus: true, script: "git diff-index --quiet HEAD -- ${env.GRAFANA_BACKUP_DIR}")
                    
                    if (changes != 0) {
                        // This quoting allows the shell to correctly execute the 'date' command.
                        sh 'git commit -m "Grafana Dashboards Backup - $(date +%Y-%m-%d_%H-%M-%S)"'
                        
                        withCredentials([string(credentialsId: 'github-creds1', variable: 'GIT_PAT')]) {
                            sh '''
                                git remote set-url origin https://github.com/joe06031990/test
                                git config credential.helper store
                                echo "https://${GIT_PAT}:@github.com" > ~/.git-credentials
                                git push origin HEAD:master
                            '''
                        }
                    } else {
                        echo "No changes detected."
                    }
                }
            }
        }
    }

    // The 'post' section defines actions that run at the end of the pipeline.
    post {
        // 'always' means this action will run regardless of whether the pipeline succeeded or failed.
        always {
            // 'cleanWs' deletes all files from the workspace, ensuring a clean start for the next run.
            cleanWs()
        }
    }
}
